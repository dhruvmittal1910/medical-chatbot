{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e2e8557d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2e8557d",
        "outputId": "76cd3aa5-503e-48cf-9660-f19e6d88fc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello\n"
          ]
        }
      ],
      "source": [
        "print(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30809bf4",
      "metadata": {
        "id": "30809bf4",
        "outputId": "aacf94ce-99c5-4ac1-db84-686a5d12bc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\projects\\\\medical-chatbot\\\\research'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7441e493",
      "metadata": {
        "id": "7441e493"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e277ef9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0e277ef9",
        "outputId": "5af01609-92d2-4ef9-91bc-e51c586cbb73"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JiF0h5m53KCW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiF0h5m53KCW",
        "outputId": "89f4f54a-2a21-4e8d-9247-0c8d184fcbd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.23)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d17266e9",
      "metadata": {
        "id": "d17266e9"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da8cc55",
      "metadata": {
        "id": "7da8cc55"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fEL8xzk03frb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEL8xzk03frb",
        "outputId": "c9343de2-eba5-4123-fbfa-b5e4ab1a097e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "06dc3555",
      "metadata": {
        "id": "06dc3555"
      },
      "outputs": [],
      "source": [
        "def extract_pdf_files(data_path):\n",
        "    # here in data folder you can add more pdfs too, loader will load all of them\n",
        "    loader=DirectoryLoader(\n",
        "        data_path,glob=\"*.pdf\",loader_cls=PyPDFLoader\n",
        "    )\n",
        "\n",
        "    documents=loader.load()\n",
        "    return documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cb6506ed",
      "metadata": {
        "id": "cb6506ed"
      },
      "outputs": [],
      "source": [
        "extracted_data=extract_pdf_files(\"sample_data\")\n",
        "# extracted_data\n",
        "# langchain returning the document format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0f9f88e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9f88e0",
        "outputId": "9e2b53d3-de9a-45cc-9673-fe937cef7952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "637"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(extracted_data) #number of pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "facc0b33",
      "metadata": {
        "id": "facc0b33"
      },
      "outputs": [],
      "source": [
        "# page content is needed and it is present in document that we get\n",
        "from typing import List\n",
        "from langchain.schema import Document\n",
        "\n",
        "def filter_to_minimal_docs(docs:List[Document])->List[Document]:\n",
        "    \"\"\"\n",
        "    Given a list of documents, i wnat to return a new list of documents that only contains the source and the page_content\n",
        "    \"\"\"\n",
        "\n",
        "    minimal_docs:List[Document]=[]\n",
        "    for doc in docs:\n",
        "        src=doc.metadata.get('source')\n",
        "        minimal_docs.append(\n",
        "            Document(\n",
        "                page_content=doc.page_content,\n",
        "                metadata={\"source\":src}\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return minimal_docs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e553a8d8",
      "metadata": {
        "id": "e553a8d8"
      },
      "outputs": [],
      "source": [
        "extracted_text=filter_to_minimal_docs(extracted_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6693dff7",
      "metadata": {
        "id": "6693dff7"
      },
      "source": [
        "# chunkning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "615167f3",
      "metadata": {
        "id": "615167f3"
      },
      "outputs": [],
      "source": [
        "def text_splitter(extracted_text):\n",
        "    # here create the chunks of the extracted data\n",
        "    text_splitter=RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=20,\n",
        "        # length_function=len\n",
        "    )\n",
        "\n",
        "    chunked_text=text_splitter.split_documents(extracted_text)\n",
        "    return chunked_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7a51f057",
      "metadata": {
        "id": "7a51f057"
      },
      "outputs": [],
      "source": [
        "len(text_splitter(extracted_text))\n",
        "texts_chunk=text_splitter(extracted_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "q6c02Jcq987f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6c02Jcq987f",
        "outputId": "e7a3b248-4ce6-47be-8ea2-c870d2c1ed34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5859"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts_chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f292e2",
      "metadata": {
        "id": "06f292e2"
      },
      "source": [
        "# do embeddings of the chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1f4e1573",
      "metadata": {
        "id": "1f4e1573"
      },
      "outputs": [],
      "source": [
        "# hugging face embedding model\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# download the pretrained embedding model we want to use\n",
        "\n",
        "def download_embedding_model():\n",
        "    \"\"\"\n",
        "    Download the model and return the hugging face embedddings\n",
        "    \"\"\"\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    embeddings=HuggingFaceEmbeddings(\n",
        "        model_name=model_name\n",
        "    )\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "31ca159c",
      "metadata": {
        "id": "31ca159c"
      },
      "outputs": [],
      "source": [
        "embeddings=download_embedding_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "av4Csle6355q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av4Csle6355q",
        "outputId": "533b636b-d709-45bf-830b-a0c2460e7514"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jwWS0reD-Sc0",
      "metadata": {
        "id": "jwWS0reD-Sc0"
      },
      "source": [
        "texting the embedding of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "zQWXSnq8-Ler",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zQWXSnq8-Ler",
        "outputId": "4a7f445a-8845-4098-b4e7-2494d2756519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384\n"
          ]
        }
      ],
      "source": [
        "print(len(list(embeddings.embed_query(\"hello i am dhruv\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "xa3IvePgE9dl",
      "metadata": {
        "id": "xa3IvePgE9dl"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m3A6_ZPe-OvG",
      "metadata": {
        "id": "m3A6_ZPe-OvG"
      },
      "outputs": [],
      "source": [
        "# store the embeddings in the vector database\n",
        "# access the pinecone and open ai api key  \n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')\n",
        "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "os.environ['PINECONE_API_KEY']=PINECONE_API_KEY\n",
        "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "_TozE6BlAhPG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "collapsed": true,
        "id": "_TozE6BlAhPG",
        "outputId": "4efc7452-fd05-422d-a673-8a4c13e961db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone\n",
            "  Downloading pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.8.3)\n",
            "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
            "  Downloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Collecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
            "Downloading pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-interface, packaging, pinecone-plugin-assistant, pinecone\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "Successfully installed packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7d11219953754b1e85432c2d71dac347",
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "kHxUM9P-AdBF",
      "metadata": {
        "id": "kHxUM9P-AdBF"
      },
      "outputs": [],
      "source": [
        "# import pinecone\n",
        "from pinecone import Pinecone\n",
        "pinecone_api_key=PINECONE_API_KEY\n",
        "\n",
        "# authenticate pinecone accrount and create a client\n",
        "pinecone_client=Pinecone(api_key=pinecone_api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "_GEqmPmIAqnk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GEqmPmIAqnk",
        "outputId": "ed856088-3d9b-44fc-b6f2-428b4c68e2fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pinecone.pinecone.Pinecone at 0x7fbf42ae2540>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pinecone_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "mpigvHiYA9SE",
      "metadata": {
        "id": "mpigvHiYA9SE"
      },
      "outputs": [],
      "source": [
        "# create index or database\n",
        "from pinecone import  ServerlessSpec\n",
        "index_name=\"medical-chatbot\"\n",
        "\n",
        "if not pinecone_client.has_index(index_name):\n",
        "  pinecone_client.create_index(\n",
        "      name=index_name,\n",
        "      dimension=384,# dimenstion of the embeddings that we got above\n",
        "      metric='cosine',\n",
        "      spec=ServerlessSpec(cloud='aws',region='us-east-1')\n",
        "  )\n",
        "\n",
        "\n",
        "# creating the index, you can check it creates a new index in db\n",
        "index=pinecone_client.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "_lQZuBrjDTsu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_lQZuBrjDTsu",
        "outputId": "f4eeb34c-163b-4eef-d648-de9f07e4e197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.12-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.12/dist-packages (from langchain_pinecone) (0.3.75)\n",
            "Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (7.3.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from langchain_pinecone) (2.0.2)\n",
            "Collecting langchain-openai>=0.3.11 (from langchain_pinecone)\n",
            "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: httpx>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from langchain_pinecone) (0.28.1)\n",
            "Requirement already satisfied: simsimd>=5.9.11 in /usr/local/lib/python3.12/dist-packages (from langchain_pinecone) (6.5.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain_pinecone) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain_pinecone) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain_pinecone) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.0->langchain_pinecone) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.4.23)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.11.7)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.3.11->langchain_pinecone) (1.106.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.3.11->langchain_pinecone) (0.11.0)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (3.12.15)\n",
            "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone)\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain_pinecone) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain_pinecone) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain_pinecone) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain_pinecone) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.17.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.11->langchain_pinecone) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.4.3)\n",
            "Downloading langchain_pinecone-0.2.12-py3-none-any.whl (25 kB)\n",
            "Downloading langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: aiohttp-retry, langchain-openai, langchain_pinecone\n",
            "Successfully installed aiohttp-retry-2.9.1 langchain-openai-0.3.32 langchain_pinecone-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "SYmaTOYKDnZY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SYmaTOYKDnZY",
        "outputId": "6267b624-4a25-49dd-a82a-9d3a710fff24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.32)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.75)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.23)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "hS2PAKxZB80N",
      "metadata": {
        "id": "hS2PAKxZB80N"
      },
      "outputs": [],
      "source": [
        "# now push the embeddings\n",
        "\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# creating embeddings using hf sentence transformer\n",
        "docSearch = PineconeVectorStore.from_documents(\n",
        "    documents=texts_chunk,\n",
        "    index=index,\n",
        "    embedding=embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "Qv38d4L3EOGG",
      "metadata": {
        "id": "Qv38d4L3EOGG"
      },
      "outputs": [],
      "source": [
        "# load a exisiting index and continue the work\n",
        "# from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# existing_docSearch=PineconeVectorStore.from_existing_index(\n",
        "#     index_name=index_name,\n",
        "#     embedding=embeddings,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7gUEMPJjHOq-",
      "metadata": {
        "id": "7gUEMPJjHOq-"
      },
      "source": [
        "# add new documents or new data to the existing knowledge base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "XbBuPRqeGy1U",
      "metadata": {
        "id": "XbBuPRqeGy1U"
      },
      "outputs": [],
      "source": [
        "# if we want to add more data t the existing pinecone index to increase the kb\n",
        "# creating a dummy documnet\n",
        "dummy=Document(\n",
        "    page_content='Lionel Messi is the best soccer player',\n",
        "    metadata={'source':'manual_entry'}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "YI5dUL8nHEav",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI5dUL8nHEav",
        "outputId": "a41b9c59-c475-4779-ad03-9c9ee90f0458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['6a717b68-6ced-4a2d-831b-2e2e3fdbe247']"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docSearch.add_documents([dummy])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7IEi3LedHZth",
      "metadata": {
        "id": "7IEi3LedHZth"
      },
      "source": [
        "# now create a retriever llm model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3e59a2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "aP0NAO4kHKD3",
      "metadata": {
        "id": "aP0NAO4kHKD3"
      },
      "outputs": [],
      "source": [
        "retriever=docSearch.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={\"k\":4}, # overlapping chunks number, get top 4 retrived sentences\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "gddpo6aeHrpb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gddpo6aeHrpb",
        "outputId": "e0247c93-a993-4cca-c595-34de5d256396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lionel Messi is the best soccer player\n",
            "be understood are among our most basic n\n",
            "(Zovirax), famciclovir (Famvir), and val\n",
            "United States. Milieu therapies (or envi\n"
          ]
        }
      ],
      "source": [
        "question='who is the best soccer player'\n",
        "retrieved_docs=retriever.invoke(question)\n",
        "# retrieved_docs\n",
        "for doc in retrieved_docs:\n",
        "  print(doc.page_content[:40])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "783KO4t6H2aR",
      "metadata": {
        "id": "783KO4t6H2aR"
      },
      "outputs": [],
      "source": [
        "# i want to refine the resposne with the llm\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatmodel=ChatOpenAI(\n",
        "    model='gpt-4o'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "d5Fz_DVeIwHP",
      "metadata": {
        "id": "d5Fz_DVeIwHP"
      },
      "outputs": [],
      "source": [
        "# create a chain, to setup the rag pipleine\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template=(\n",
        "    \"You are a Medical chatbot assistant that is trained for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrived context to answer the user's question properly.\"\n",
        "    \" If you do not know the answer, apologize for the inconvenience, do not give\"\n",
        "    \" misinformation. say that you do not know the answer. \"\n",
        "    \"Use the retrieved context properly and keep the answers concise \\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt=ChatPromptTemplate.from_messages( # Use from_messages for multiple roles\n",
        "\n",
        "        [ # Pass a list of tuples\n",
        "            (\"system\",prompt_template), #the system prompt\n",
        "            (\"human\",\"{input}\") #input from the user\n",
        "        ]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzCEH1_MM95G",
      "metadata": {
        "id": "GzCEH1_MM95G"
      },
      "outputs": [],
      "source": [
        "# create a chain\n",
        "# ChatPromptTemplate = defines how to ask\n",
        "\n",
        "# create_stuff_documents_chain = defines how to insert docs into the prompt\n",
        "\n",
        "# create_retrieval_chain = glues retriever + doc chain into a single RAG pipeline\n",
        "\n",
        "question_answer_chain=create_stuff_documents_chain(chatmodel,prompt)\n",
        "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "ZQ7yFA62PZTu",
      "metadata": {
        "id": "ZQ7yFA62PZTu"
      },
      "outputs": [],
      "source": [
        "que=\"who is dhruv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "nbsjfjDCO9rh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsjfjDCO9rh",
        "outputId": "42164bc4-d7df-4e48-cd04-2e43d577a192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but I do not have any information on someone named Dhruv based on the provided context. If you have more specific details or context regarding who Dhruv might be, feel free to share.\n"
          ]
        }
      ],
      "source": [
        "print(rag_chain.invoke({\"input\":que})['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CKOaZMKzPEeZ",
      "metadata": {
        "id": "CKOaZMKzPEeZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
